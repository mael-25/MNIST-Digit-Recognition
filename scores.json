{
    "Logs/MNIST-epochs=50-layers=7-9.pt": {
        "score": 0.9754,
        "max-score": 0.9778,
        "max-score-epoch": 49,
        "epochs": 50,
        "validation-results": {
            "1": 0.8772,
            "2": 0.903,
            "3": 0.9246,
            "4": 0.9451,
            "5": 0.949,
            "6": 0.9389,
            "7": 0.9258,
            "8": 0.9385,
            "9": 0.9499,
            "10": 0.9474,
            "11": 0.9497,
            "12": 0.9609,
            "13": 0.9447,
            "14": 0.9526,
            "15": 0.9454,
            "16": 0.9568,
            "17": 0.9607,
            "18": 0.9577,
            "19": 0.9431,
            "20": 0.9613,
            "21": 0.9632,
            "22": 0.9655,
            "23": 0.9549,
            "24": 0.9627,
            "25": 0.9636,
            "26": 0.9659,
            "27": 0.9699,
            "28": 0.9736,
            "29": 0.9615,
            "30": 0.9743,
            "31": 0.9745,
            "32": 0.9736,
            "33": 0.9749,
            "34": 0.9674,
            "35": 0.9712,
            "36": 0.973,
            "37": 0.9754,
            "38": 0.9742,
            "39": 0.9711,
            "40": 0.9719,
            "41": 0.9742,
            "42": 0.9731,
            "43": 0.972,
            "44": 0.9737,
            "45": 0.9744,
            "46": 0.9768,
            "47": 0.9757,
            "48": 0.9737,
            "49": 0.9778,
            "50": 0.9754
        },
        "learning-rate": {
            "1": 0.01,
            "5": 0.0075,
            "10": 0.005,
            "20": 0.003,
            "25": 0.0025,
            "30": 0.001,
            "45": 0.0005
        },
        "batch-size": 32,
        "weight-decay": 0.005,
        "model-class-type": "linear",
        "model": "Sequential(\n  (0): Linear(in_features=784, out_features=512, bias=True)\n  (1): Dropout(p=0.005, inplace=False)\n  (2): ReLU()\n  (3): Linear(in_features=512, out_features=256, bias=True)\n  (4): Dropout(p=0.005, inplace=False)\n  (5): ReLU()\n  (6): Linear(in_features=256, out_features=128, bias=True)\n  (7): Dropout(p=0.005, inplace=False)\n  (8): ReLU()\n  (9): Linear(in_features=128, out_features=64, bias=True)\n  (10): Dropout(p=0.005, inplace=False)\n  (11): ReLU()\n  (12): Linear(in_features=64, out_features=32, bias=True)\n  (13): Dropout(p=0.005, inplace=False)\n  (14): ReLU()\n  (15): Linear(in_features=32, out_features=16, bias=True)\n  (16): Dropout(p=0.005, inplace=False)\n  (17): ReLU()\n  (18): Linear(in_features=16, out_features=10, bias=True)\n  (19): LogSoftmax(dim=1)\n)"
    },
    "Logs/MNIST-epochs=10-layers=7-1.pt": {
        "score": 0.9536,
        "max-score": 0.9536,
        "max-score-epoch": 10,
        "epochs": 10,
        "validation-results": {
            "1": 0.8759,
            "2": 0.9263,
            "3": 0.9156,
            "4": 0.9388,
            "5": 0.9462,
            "6": 0.9365,
            "7": 0.9386,
            "8": 0.9471,
            "9": 0.9355,
            "10": 0.9536
        },
        "learning-rate": {
            "1": 0.01,
            "5": 0.0075,
            "10": 0.005,
            "20": 0.003,
            "25": 0.0025,
            "30": 0.001,
            "45": 0.0005
        },
        "batch-size": 32,
        "weight-decay": 0.005,
        "model-class-type": "linear",
        "model": "Sequential(\n  (0): Linear(in_features=784, out_features=512, bias=True)\n  (1): Dropout(p=0.005, inplace=False)\n  (2): ReLU()\n  (3): Linear(in_features=512, out_features=256, bias=True)\n  (4): Dropout(p=0.005, inplace=False)\n  (5): ReLU()\n  (6): Linear(in_features=256, out_features=128, bias=True)\n  (7): Dropout(p=0.005, inplace=False)\n  (8): ReLU()\n  (9): Linear(in_features=128, out_features=64, bias=True)\n  (10): Dropout(p=0.005, inplace=False)\n  (11): ReLU()\n  (12): Linear(in_features=64, out_features=32, bias=True)\n  (13): Dropout(p=0.005, inplace=False)\n  (14): ReLU()\n  (15): Linear(in_features=32, out_features=16, bias=True)\n  (16): Dropout(p=0.005, inplace=False)\n  (17): ReLU()\n  (18): Linear(in_features=16, out_features=10, bias=True)\n  (19): LogSoftmax(dim=1)\n)"
    },
    "Logs/MNIST-epochs=10-layers=7-2.pt": {
        "score": 0.9515,
        "max-score": 0.9532,
        "max-score-epoch": 8,
        "epochs": 10,
        "validation-results": {
            "1": 0.8989,
            "2": 0.8688,
            "3": 0.9242,
            "4": 0.9431,
            "5": 0.9294,
            "6": 0.9239,
            "7": 0.9319,
            "8": 0.9532,
            "9": 0.8959,
            "10": 0.9515
        },
        "learning-rate": {
            "1": 0.01,
            "5": 0.0075,
            "10": 0.005,
            "20": 0.003,
            "25": 0.0025,
            "30": 0.001,
            "45": 0.0005
        },
        "batch-size": 32,
        "weight-decay": 0.005,
        "model-class-type": "linear",
        "model": "Sequential(\n  (0): Linear(in_features=784, out_features=512, bias=True)\n  (1): Dropout(p=0.005, inplace=False)\n  (2): ReLU()\n  (3): Linear(in_features=512, out_features=256, bias=True)\n  (4): Dropout(p=0.005, inplace=False)\n  (5): ReLU()\n  (6): Linear(in_features=256, out_features=128, bias=True)\n  (7): Dropout(p=0.005, inplace=False)\n  (8): ReLU()\n  (9): Linear(in_features=128, out_features=64, bias=True)\n  (10): Dropout(p=0.005, inplace=False)\n  (11): ReLU()\n  (12): Linear(in_features=64, out_features=32, bias=True)\n  (13): Dropout(p=0.005, inplace=False)\n  (14): ReLU()\n  (15): Linear(in_features=32, out_features=16, bias=True)\n  (16): Dropout(p=0.005, inplace=False)\n  (17): ReLU()\n  (18): Linear(in_features=16, out_features=10, bias=True)\n  (19): LogSoftmax(dim=1)\n)"
    },
    "Logs/MNIST-epochs=50-layers=7-8.pt": {
        "score": 0.1135,
        "max-score": 0.1135,
        "max-score-epoch": 1,
        "epochs": 50,
        "validation-results": {
            "1": 0.1135,
            "2": 0.0958,
            "3": 0.1028,
            "4": 0.101,
            "5": 0.1135,
            "6": 0.1135,
            "7": 0.1028,
            "8": 0.1028,
            "9": 0.1135,
            "10": 0.1135,
            "11": 0.1135,
            "12": 0.1135,
            "13": 0.1135,
            "14": 0.1135,
            "15": 0.1135,
            "16": 0.1009,
            "17": 0.1135,
            "18": 0.1135,
            "19": 0.1135,
            "20": 0.1135,
            "21": 0.1009,
            "22": 0.1135,
            "23": 0.1135,
            "24": 0.1135,
            "25": 0.1135,
            "26": 0.1135,
            "27": 0.1135,
            "28": 0.1135,
            "29": 0.1135,
            "30": 0.1135,
            "31": 0.1135,
            "32": 0.1135,
            "33": 0.1135,
            "34": 0.1135,
            "35": 0.1135,
            "36": 0.1135,
            "37": 0.1135,
            "38": 0.1135,
            "39": 0.1135,
            "40": 0.1135,
            "41": 0.1135,
            "42": 0.1135,
            "43": 0.1135,
            "44": 0.1135,
            "45": 0.1135,
            "46": 0.1135,
            "47": 0.1135,
            "48": 0.1135,
            "49": 0.1135,
            "50": 0.1135
        },
        "learning-rate": {
            "10": 0.02,
            "25": 0.004,
            "40": 0.0008
        },
        "batch-size": 32,
        "weight-decay": 0.005,
        "model-class-type": "linear",
        "model": "Sequential(\n  (0): Linear(in_features=784, out_features=512, bias=True)\n  (1): Dropout(p=0.005, inplace=False)\n  (2): ReLU()\n  (3): Linear(in_features=512, out_features=256, bias=True)\n  (4): Dropout(p=0.005, inplace=False)\n  (5): ReLU()\n  (6): Linear(in_features=256, out_features=128, bias=True)\n  (7): Dropout(p=0.005, inplace=False)\n  (8): ReLU()\n  (9): Linear(in_features=128, out_features=64, bias=True)\n  (10): Dropout(p=0.005, inplace=False)\n  (11): ReLU()\n  (12): Linear(in_features=64, out_features=32, bias=True)\n  (13): Dropout(p=0.005, inplace=False)\n  (14): ReLU()\n  (15): Linear(in_features=32, out_features=16, bias=True)\n  (16): Dropout(p=0.005, inplace=False)\n  (17): ReLU()\n  (18): Linear(in_features=16, out_features=10, bias=True)\n  (19): LogSoftmax(dim=1)\n)"
    },
    "Logs/MNIST-epochs=5-layers=5-1.pt": {
        "score": 0.1135,
        "max-score": 0.1135,
        "max-score-epoch": 2,
        "epochs": 5,
        "validation-results": {
            "1": 0.1028,
            "2": 0.1135,
            "3": 0.1135,
            "4": 0.1135,
            "5": 0.1135
        },
        "learning-rate": {
            "3": 0.0015,
            "6": 0.00030000000000000003,
            "9": 6.000000000000001e-05
        },
        "batch-size": 2,
        "weight-decay": 0.005,
        "model-class-type": "conv2d",
        "model": "Sequential(\n  (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n  (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (2): ReLU()\n  (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n  (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (5): ReLU()\n  (6): AvgPool2d(kernel_size=8, stride=8, padding=0)\n  (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (8): ReLU()\n  (9): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n  (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (11): ReLU()\n  (12): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n  (13): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (14): ReLU()\n  (15): Conv2d(32, 10, kernel_size=(1, 1), stride=(1, 1))\n  (16): LogSoftmax(dim=1)\n)"
    },
    "Logs/MNIST-epochs=1-layers=5-1.pt": {
        "score": 0.1117,
        "max-score": 0.1117,
        "max-score-epoch": 1,
        "epochs": 1,
        "validation-results": {
            "1": 0.1117
        },
        "learning-rate": {
            "3": 0.0015,
            "6": 0.00030000000000000003,
            "9": 6.000000000000001e-05
        },
        "batch-size": 64,
        "weight-decay": 0.005,
        "model-class-type": "conv2d",
        "model": "Sequential(\n  (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n  (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (2): ReLU()\n  (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n  (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (5): ReLU()\n  (6): AvgPool2d(kernel_size=8, stride=8, padding=0)\n  (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (8): ReLU()\n  (9): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n  (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (11): ReLU()\n  (12): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n  (13): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (14): ReLU()\n  (15): Conv2d(32, 10, kernel_size=(1, 1), stride=(1, 1))\n  (16): LogSoftmax(dim=1)\n)"
    }
}